{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e875c8d02dc847d4827deaa1ab13def5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bbd0e105ffd0415fbf8f995780c6fc8c","IPY_MODEL_b17fb0004c8d4d46883bb9b4d878b5e3","IPY_MODEL_74662d4c5919495ba20ec3aaf0d49b5c"],"layout":"IPY_MODEL_5811e245096d4d609916ee9b5fe5b4df"}},"bbd0e105ffd0415fbf8f995780c6fc8c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2feb0b00e62046bbbf9945d5f0d004d9","placeholder":"​","style":"IPY_MODEL_b335b203f6714cfab84164bf69f5e56b","value":"100%"}},"b17fb0004c8d4d46883bb9b4d878b5e3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca5d423e38d144ea862f7a22cef11b03","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0c477bd160b04c0dbab79072953773fd","value":50}},"74662d4c5919495ba20ec3aaf0d49b5c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_57bb1d7450c04b42bd58400137c5e628","placeholder":"​","style":"IPY_MODEL_149bc3f55e7d42da9ff13a590e931d4f","value":" 50/50 [20:59&lt;00:00, 24.96s/it]"}},"5811e245096d4d609916ee9b5fe5b4df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2feb0b00e62046bbbf9945d5f0d004d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b335b203f6714cfab84164bf69f5e56b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca5d423e38d144ea862f7a22cef11b03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c477bd160b04c0dbab79072953773fd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"57bb1d7450c04b42bd58400137c5e628":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"149bc3f55e7d42da9ff13a590e931d4f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"vroxxU1Mia53","executionInfo":{"status":"ok","timestamp":1699976547061,"user_tz":300,"elapsed":3248,"user":{"displayName":"Ziggy Stardust","userId":"08843263779895663427"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","import tensorflow as tf\n","import tensorflow_probability as tfp\n","import time"]},{"cell_type":"code","source":["(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n","def preprocess_images(images):\n","  images = images.reshape((images.shape[0], 28,28)) / 255.\n","  return images\n","\n","train_images = preprocess_images(train_images)\n","test_images = preprocess_images(test_images)\n","\n","train_labels = np.expand_dims(train_labels,axis=-1)\n","test_labels = np.expand_dims(test_labels,axis=-1)\n","train_size = 60000\n","batch_size = 1024\n","test_size = 10000\n","\n","train_images = tf.expand_dims(train_images, axis = -1)\n","test_images = tf.expand_dims(test_images, axis = -1)"],"metadata":{"id":"gWJyaObmidrZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699976551783,"user_tz":300,"elapsed":4728,"user":{"displayName":"Ziggy Stardust","userId":"08843263779895663427"}},"outputId":"4c53bb93-dcef-444c-efb2-f7392e2b78e6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 1s 0us/step\n"]}]},{"cell_type":"code","source":["train_dataset = (tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n","                 .shuffle(train_size,reshuffle_each_iteration=True).batch(batch_size,drop_remainder=True))\n","test_dataset = (tf.data.Dataset.from_tensor_slices((test_images,test_labels))\n","                .shuffle(test_size).batch(batch_size,drop_remainder=True))"],"metadata":{"id":"RLpHtoDrieVN","executionInfo":{"status":"ok","timestamp":1699976552019,"user_tz":300,"elapsed":240,"user":{"displayName":"Ziggy Stardust","userId":"08843263779895663427"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["train_labels.shape, train_images.shape"],"metadata":{"id":"j1hklQlEifdX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699976552019,"user_tz":300,"elapsed":3,"user":{"displayName":"Ziggy Stardust","userId":"08843263779895663427"}},"outputId":"366c8b22-9fb4-488b-910f-1ec245ee25ab"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((60000, 1), TensorShape([60000, 28, 28, 1]))"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["import tensorflow as tf\n","tf.get_logger().setLevel('ERROR')"],"metadata":{"id":"cFhcjyaogR6p","executionInfo":{"status":"ok","timestamp":1699976552019,"user_tz":300,"elapsed":2,"user":{"displayName":"Ziggy Stardust","userId":"08843263779895663427"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["\n","class CustomDropout(tf.keras.layers.Layer):\n","    def __init__(self, rate, input_dim, **kwargs):\n","        super(CustomDropout, self).__init__(**kwargs)\n","        self.rate = 1-rate\n","        self.input_dim = input_dim\n","        self.mask_w = self.add_weight(shape=(self.input_dim,n_decision_makers), trainable=True)\n","        self.mask_b = self.add_weight(shape=(n_decision_makers,), initializer=\"zeros\",trainable=True)\n","\n","    def call(self, inputs, label, training=None):\n","        if training:\n","          scce = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n","          loss = scce(tf.tile(tf.transpose([label],perm = [1,2,0]),[1,n_decision_makers,1]),inputs)\n","          threshold = tfp.stats.percentile(loss, q=self.rate*100)\n","          dropout_mask = (loss<=threshold) ## <= 1-rate keep the best 10%\n","          mask = tf.tile(tf.expand_dims(dropout_mask, axis=-1), [1,1,10])\n","\n","          mask_pred = tf.nn.sigmoid(tf.matmul(tf.keras.layers.Flatten()(inputs), self.mask_w)+self.mask_b)\n","          mask_pred = tf.tile(mask_pred, [1,10])\n","          return tf.multiply(tf.keras.layers.Reshape((n_decision_makers,10))(mask_pred), inputs), tf.cast(mask,'float32'), mask_pred\n","        else:\n","          mask_pred = tf.nn.sigmoid(tf.matmul(tf.keras.layers.Flatten()(inputs), self.mask_w)+self.mask_b)\n","          mask_pred = tf.tile(mask_pred, [1,10])\n","          return tf.multiply(tf.keras.layers.Reshape((n_decision_makers,10))(mask_pred),inputs),tf.ones(shape = (batch_size,n_decision_makers,10)),mask_pred ## reshape self.mask"],"metadata":{"id":"JR8nmWt3guXi","executionInfo":{"status":"ok","timestamp":1699976552019,"user_tz":300,"elapsed":2,"user":{"displayName":"Ziggy Stardust","userId":"08843263779895663427"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["n_decision_makers = 4  #100\n","class MyModel(tf.keras.Model):\n","    def __init__(self,**kwargs):\n","      super(MyModel,self).__init__(**kwargs)\n","\n","      self.flat1 = tf.keras.layers.Flatten()\n","      self.flat2 = tf.keras.layers.Flatten()\n","      self.flat3 = tf.keras.layers.Flatten()\n","      self.flat4 = tf.keras.layers.Flatten()\n","      self.flat5 = tf.keras.layers.Flatten()\n","      self.flat6 = tf.keras.layers.Flatten()\n","      self.reshape1 = tf.keras.layers.Reshape((n_decision_makers,10))\n","      self.reshape2 = tf.keras.layers.Reshape((n_decision_makers,10))\n","      self.dropout1 = CustomDropout(0.3,n_decision_makers*10)\n","\n","      self.dropout4 = tf.keras.layers.Dropout(0.2)\n","      self.dropout5 = tf.keras.layers.Dropout(0.2)\n","\n","      self.pool1 = tf.keras.layers.MaxPooling2D((2, 2))\n","      self.pool2 = tf.keras.layers.MaxPooling2D((2, 2))\n","\n","      self.conv1 = tf.keras.layers.Conv2D(64, 3, activation='relu',padding='same',kernel_regularizer=tf.keras.regularizers.l1(l=0.01),kernel_initializer='he_uniform',)\n","      self.conv11 = tf.keras.layers.Conv2D(128, 3, activation='relu',padding='same',kernel_regularizer=tf.keras.regularizers.l1(l=0.01),kernel_initializer='he_uniform',)\n","      self.dense1 = tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n","      self.batchnorm1 = tf.keras.layers.BatchNormalization()\n","\n","      self.conv2 = tf.keras.layers.Conv2D(128, 3, activation='relu',padding='same',kernel_regularizer=tf.keras.regularizers.l1(l=0.01),kernel_initializer='he_uniform',)\n","      self.conv22 = tf.keras.layers.Conv2D(64, 3, activation='relu',padding='same',kernel_regularizer=tf.keras.regularizers.l1(l=0.01),kernel_initializer='he_uniform',)\n","      self.dense2 = tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n","      self.batchnorm2 = tf.keras.layers.BatchNormalization()\n","      self.dense5 = tf.keras.layers.Dense(n_decision_makers*10,activation=tf.nn.relu)\n","\n","      self.dense7 = tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n","\n","    def call(self, input):\n","\n","      [input, label] = input\n","      hidden_conv1 = self.dropout4(self.batchnorm1(self.pool1(self.conv1(self.conv11(input)))))\n","      hidden_conv1_reshape = self.flat4(hidden_conv1)\n","      hidden_conv1_out = self.dense1(hidden_conv1_reshape)\n","\n","      hidden_conv2 = self.dropout5(self.batchnorm2(self.pool2(self.conv2(self.conv22(hidden_conv1)))))\n","      hidden_conv2_reshape = self.flat5(hidden_conv2)\n","      hidden_conv2_out = self.dense2(hidden_conv2_reshape)\n","\n","      hidden1 = self.dense5(hidden_conv2_reshape)\n","\n","      hidden1_reshape = self.reshape1(hidden1)\n","      hidden1_softmax = tf.nn.softmax(hidden1_reshape)\n","      hidden1_out,hidden1_true_mask,hidden1_pred_mask = self.dropout1(hidden1_softmax,label)\n","      outputs = self.dense7(self.flat1(hidden1_out)) #leader outputs\n","\n","      return self.flat2(hidden1_true_mask), hidden1_pred_mask, hidden_conv1_out, hidden_conv2_out, hidden1_out, outputs"],"metadata":{"id":"Xrh9nKBQg-CP","executionInfo":{"status":"ok","timestamp":1699976552019,"user_tz":300,"elapsed":2,"user":{"displayName":"Ziggy Stardust","userId":"08843263779895663427"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["model = MyModel()\n","model([tf.zeros((batch_size, 28, 28, 1)),tf.zeros((batch_size, 1))])\n","model.summary()"],"metadata":{"id":"gZ4fQprxg_1d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699976560437,"user_tz":300,"elapsed":8420,"user":{"displayName":"Ziggy Stardust","userId":"08843263779895663427"}},"outputId":"13ceebef-cbbb-4ba9-bfa2-280dd01b85bc"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"my_model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten (Flatten)           multiple                  0         \n","                                                                 \n"," flatten_1 (Flatten)         multiple                  0         \n","                                                                 \n"," flatten_2 (Flatten)         multiple                  0 (unused)\n","                                                                 \n"," flatten_3 (Flatten)         multiple                  0         \n","                                                                 \n"," flatten_4 (Flatten)         multiple                  0         \n","                                                                 \n"," flatten_5 (Flatten)         multiple                  0 (unused)\n","                                                                 \n"," reshape (Reshape)           multiple                  0         \n","                                                                 \n"," reshape_1 (Reshape)         multiple                  0 (unused)\n","                                                                 \n"," custom_dropout (CustomDrop  multiple                  164       \n"," out)                                                            \n","                                                                 \n"," dropout (Dropout)           multiple                  0         \n","                                                                 \n"," dropout_1 (Dropout)         multiple                  0         \n","                                                                 \n"," max_pooling2d (MaxPooling2  multiple                  0         \n"," D)                                                              \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  multiple                  0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d (Conv2D)             multiple                  73792     \n","                                                                 \n"," conv2d_1 (Conv2D)           multiple                  1280      \n","                                                                 \n"," dense (Dense)               multiple                  125450    \n","                                                                 \n"," batch_normalization (Batch  multiple                  256       \n"," Normalization)                                                  \n","                                                                 \n"," conv2d_2 (Conv2D)           multiple                  73856     \n","                                                                 \n"," conv2d_3 (Conv2D)           multiple                  36928     \n","                                                                 \n"," dense_1 (Dense)             multiple                  62730     \n","                                                                 \n"," batch_normalization_1 (Bat  multiple                  512       \n"," chNormalization)                                                \n","                                                                 \n"," dense_2 (Dense)             multiple                  250920    \n","                                                                 \n"," dense_3 (Dense)             multiple                  410       \n","                                                                 \n","=================================================================\n","Total params: 626298 (2.39 MB)\n","Trainable params: 625914 (2.39 MB)\n","Non-trainable params: 384 (1.50 KB)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["local_loss"],"metadata":{"id":"C8UDXjuSmqKu"}},{"cell_type":"code","source":["from keras import backend as K\n","\n","\n","train_loss, test_loss = tf.keras.metrics.Mean(),tf.keras.metrics.Mean()\n","mask_loss = tf.keras.metrics.Mean()\n","train_acc = tf.keras.metrics.SparseCategoricalAccuracy('train_accuracy')\n","test_acc = tf.keras.metrics.SparseCategoricalAccuracy('test_accuracy')\n","\n","\n","initial_learning_rate = 1e-4\n","lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate,\n","    decay_steps=100000,\n","    decay_rate=0.96,\n","    staircase=True)\n","\n","optimizer_mask = tf.keras.optimizers.Adam()\n","optimizer = tf.keras.optimizers.legacy.Adam(learning_rate = 5e-4)\n","\n","\n","scce = tf.keras.losses.SparseCategoricalCrossentropy()\n","cce = tf.keras.losses.BinaryCrossentropy()\n","\n","def compute_loss(hidden1_true_mask, hidden1_pred_mask, conv1, conv2, hidden1, y, output):\n","  loss_local_conv1 = scce(y,conv1)\n","  loss_local_conv2 = scce(y,conv2)\n","\n","  loss_local_hidden1 = scce(tf.tile(y, [1,n_decision_makers]),hidden1)\n","\n","  loss = scce(y,output)\n","\n","  loss_mask = cce(hidden1_true_mask, hidden1_pred_mask)\n","\n","  return loss, loss_mask, loss_local_conv1, loss_local_conv2, loss_local_hidden1\n","\n","def compute_loss_mask(hidden1_true_mask, hidden1_pred_mask):\n","  loss_mask = cce(hidden1_true_mask, hidden1_pred_mask)\n","\n","  return loss_mask\n","\n","def compute_acc(model, x, y):\n","  _,_,_,_,_,output = model([x,y])\n","  acc = tf.keras.metrics.sparse_categorical_accuracy(y, output)\n","  return acc\n","\n","def train_step(model, x, y, optimizer, lda=1.0):\n","  with tf.GradientTape(persistent =True) as tape:\n","    hidden1_true_mask, hidden1_pred_mask, conv1, conv2, hidden1, output = model([x,y], training=True)\n","    loss, loss_mask, loss_local_conv1, loss_local_conv2, loss_local_hidden1 = compute_loss(hidden1_true_mask, hidden1_pred_mask, conv1, conv2, hidden1, y, output)\n","\n","  gradients_global = tape.gradient(loss, model.layers[-1].trainable_variables)\n","  optimizer.apply_gradients(zip(gradients_global, model.layers[-1].trainable_variables))\n","\n","  gradients_local = tape.gradient(loss_local_hidden1, model.layers[-2].trainable_variables)\n","  optimizer.apply_gradients(zip(gradients_local, model.layers[-2].trainable_variables))\n","\n","  gradients_local = tape.gradient(loss_local_conv2,model.trainable_variables[10:17])\n","  optimizer.apply_gradients(zip(gradients_local, model.trainable_variables[10:17]))\n","\n","  gradients_local = tape.gradient(loss_local_conv1,model.trainable_variables[2:10])\n","  optimizer.apply_gradients(zip(gradients_local, model.trainable_variables[2:10]))\n","\n","  gradients_local = tape.gradient(loss_mask, model.layers[-15].trainable_variables)\n","\n","  # print(gradients_local)\n","\n","  # Multiplying each gradient in the list by lda\n","  scaled_gradients = [gradient * lda if gradient is not None else None for gradient in gradients_local]\n","\n","  # print(scaled_gradients)\n","\n","  optimizer_mask.apply_gradients(zip(scaled_gradients, model.layers[-15].trainable_variables))\n","\n","  train_acc(y,output)\n","  train_loss(loss)\n","\n","  for i in range(3):\n","    with tf.GradientTape(persistent =True) as tape:\n","      hidden1_true_mask, hidden1_pred_mask, _ ,_,_,_= model([x,y], training=True)\n","      loss_mask = compute_loss_mask(hidden1_true_mask, hidden1_pred_mask)\n","    gradients_local = tape.gradient(loss_mask, model.layers[-15].trainable_variables)\n","    optimizer_mask.apply_gradients(zip(gradients_local, model.layers[-15].trainable_variables))\n","\n","  mask_loss(loss_mask)\n","\n","def test_step(model, x, y):\n","  _,_,_,_,_,output = model([x,y])\n","  scce = tf.keras.losses.SparseCategoricalCrossentropy()\n","  loss = scce(y, output)\n","\n","  test_loss(loss)\n","  test_acc(y, output)"],"metadata":{"id":"sziwIIFXmpIE","executionInfo":{"status":"ok","timestamp":1699976560437,"user_tz":300,"elapsed":20,"user":{"displayName":"Ziggy Stardust","userId":"08843263779895663427"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"tko6VF29kaGl"}},{"cell_type":"code","source":["%load_ext tensorboard"],"metadata":{"id":"5McPKfgmhb1I","executionInfo":{"status":"ok","timestamp":1699976560437,"user_tz":300,"elapsed":19,"user":{"displayName":"Ziggy Stardust","userId":"08843263779895663427"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import datetime\n","\n","\n","!rm -rf ./logs/"],"metadata":{"id":"bnocUEi_myqj","executionInfo":{"status":"ok","timestamp":1699976560437,"user_tz":300,"elapsed":18,"user":{"displayName":"Ziggy Stardust","userId":"08843263779895663427"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","train_log_dir = 'logs/gradient_tape/' + current_time + str(n_decision_makers)+'dropout/train'\n","test_log_dir = 'logs/gradient_tape/' + current_time + str(n_decision_makers)+'dropout/test'\n","train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n","test_summary_writer = tf.summary.create_file_writer(test_log_dir)"],"metadata":{"id":"kyEt_DPXmzqO","executionInfo":{"status":"ok","timestamp":1699976560437,"user_tz":300,"elapsed":5,"user":{"displayName":"Ziggy Stardust","userId":"08843263779895663427"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i6OQGznwt6b0","executionInfo":{"status":"ok","timestamp":1699976615303,"user_tz":300,"elapsed":54871,"user":{"displayName":"Ziggy Stardust","userId":"08843263779895663427"}},"outputId":"e3cf0891-11e5-4e1a-e347-be16144704ff"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["EPOCHS = 50\n","from tqdm.notebook import tqdm\n","\n","import time\n","\n","txt_path = '/content/drive/MyDrive/Research/DPhil Research/ICLR_2024/' + 'MNIST_LFNN_BPfree_history_0.txt'\n","\n","with open(txt_path, 'w') as file:\n","  # for l in [0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0]:\n","  for l in [0]:\n","    print(\"----------------------------------------------\", file=file)\n","    print(\"Lambda: \", l, file=file)\n","    print(\"----------------------------------------------\")\n","    print(\"Lambda: \", l)\n","    for epoch in tqdm(range(0, 0+EPOCHS)):\n","      start=time.time()\n","      for i, (train_x, train_y) in enumerate(train_dataset):\n","        train_step(model, train_x, train_y, optimizer, lda=l)\n","\n","      with train_summary_writer.as_default():\n","        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n","        tf.summary.scalar('loss', mask_loss.result(), step=epoch)\n","        tf.summary.scalar('accuracy', train_acc.result(), step=epoch)\n","\n","      for test_x, test_y in test_dataset:\n","        test_step(model, test_x, test_y)\n","      with test_summary_writer.as_default():\n","        tf.summary.scalar('loss', test_loss.result(), step=epoch)\n","        tf.summary.scalar('accuracy', test_acc.result(), step=epoch)\n","\n","      template = 'Epoch {}, Loss: {}, Accuracy: {}, MaskLoss: {}, Test Loss: {}, Test Accuracy: {}'\n","      print(template.format(epoch+1,\n","                            train_loss.result(),\n","                            train_acc.result()*100,\n","                            mask_loss.result(),\n","                            test_loss.result(),\n","                            test_acc.result()*100), file=file)\n","\n","      print(template.format(epoch+1,\n","                            train_loss.result(),\n","                            train_acc.result()*100,\n","                            mask_loss.result(),\n","                            test_loss.result(),\n","                            test_acc.result()*100))\n","\n","      train_loss.reset_states()\n","      test_loss.reset_states()\n","      mask_loss.reset_states()\n","      train_acc.reset_states()\n","      test_acc.reset_states()"],"metadata":{"id":"qKu1yyD9m0v8","colab":{"base_uri":"https://localhost:8080/","height":978,"referenced_widgets":["e875c8d02dc847d4827deaa1ab13def5","bbd0e105ffd0415fbf8f995780c6fc8c","b17fb0004c8d4d46883bb9b4d878b5e3","74662d4c5919495ba20ec3aaf0d49b5c","5811e245096d4d609916ee9b5fe5b4df","2feb0b00e62046bbbf9945d5f0d004d9","b335b203f6714cfab84164bf69f5e56b","ca5d423e38d144ea862f7a22cef11b03","0c477bd160b04c0dbab79072953773fd","57bb1d7450c04b42bd58400137c5e628","149bc3f55e7d42da9ff13a590e931d4f"]},"executionInfo":{"status":"ok","timestamp":1699977875686,"user_tz":300,"elapsed":1260389,"user":{"displayName":"Ziggy Stardust","userId":"08843263779895663427"}},"outputId":"32b7f990-62f3-4459-8702-d59b6b4f5ce2"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------\n","Lambda:  0\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e875c8d02dc847d4827deaa1ab13def5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 2.238286256790161, Accuracy: 25.631397247314453, MaskLoss: 0.6386613249778748, Test Loss: 2.148850679397583, Test Accuracy: 29.00390625\n","Epoch 2, Loss: 1.999618649482727, Accuracy: 40.72097396850586, MaskLoss: 0.5744401812553406, Test Loss: 1.8643097877502441, Test Accuracy: 59.60286331176758\n","Epoch 3, Loss: 1.7283999919891357, Accuracy: 85.89708709716797, MaskLoss: 0.5775113105773926, Test Loss: 1.5942553281784058, Test Accuracy: 97.99262237548828\n","Epoch 4, Loss: 1.4942045211791992, Accuracy: 98.54357147216797, MaskLoss: 0.5723288059234619, Test Loss: 1.3876866102218628, Test Accuracy: 98.8498306274414\n","Epoch 5, Loss: 1.3037165403366089, Accuracy: 98.89379119873047, MaskLoss: 0.5725442171096802, Test Loss: 1.2119641304016113, Test Accuracy: 98.828125\n","Epoch 6, Loss: 1.1419755220413208, Accuracy: 99.08910369873047, MaskLoss: 0.5724127292633057, Test Loss: 1.0677860975265503, Test Accuracy: 98.86067199707031\n","Epoch 7, Loss: 1.007897973060608, Accuracy: 99.23895263671875, MaskLoss: 0.5726555585861206, Test Loss: 0.9475566148757935, Test Accuracy: 98.91493225097656\n","Epoch 8, Loss: 0.8941084742546082, Accuracy: 99.35513305664062, MaskLoss: 0.5732492804527283, Test Loss: 0.848421573638916, Test Accuracy: 98.73046875\n","Epoch 9, Loss: 0.8026950359344482, Accuracy: 99.3584976196289, MaskLoss: 0.5790624022483826, Test Loss: 0.7533108592033386, Test Accuracy: 99.06684112548828\n","Epoch 10, Loss: 0.7057457566261292, Accuracy: 99.47299194335938, MaskLoss: 0.5842379331588745, Test Loss: 0.6680035591125488, Test Accuracy: 99.2404556274414\n","Epoch 11, Loss: 0.6307314038276672, Accuracy: 99.55886840820312, MaskLoss: 0.5840963125228882, Test Loss: 0.5993201732635498, Test Accuracy: 99.2404556274414\n","Epoch 12, Loss: 0.5654386281967163, Accuracy: 99.58074951171875, MaskLoss: 0.5904431343078613, Test Loss: 0.5233838558197021, Test Accuracy: 99.20790100097656\n","Epoch 13, Loss: 0.4858812391757965, Accuracy: 99.61947631835938, MaskLoss: 0.5996776223182678, Test Loss: 0.463760644197464, Test Accuracy: 99.3381118774414\n","Epoch 14, Loss: 0.43066149950027466, Accuracy: 99.66999053955078, MaskLoss: 0.5996763706207275, Test Loss: 0.4124211072921753, Test Accuracy: 99.34895324707031\n","Epoch 15, Loss: 0.38517260551452637, Accuracy: 99.70703125, MaskLoss: 0.5974804162979126, Test Loss: 0.3761075735092163, Test Accuracy: 99.20790100097656\n","Epoch 16, Loss: 0.3487330675125122, Accuracy: 99.74238586425781, MaskLoss: 0.5967042446136475, Test Loss: 0.3415651023387909, Test Accuracy: 99.2947006225586\n","Epoch 17, Loss: 0.3067314922809601, Accuracy: 99.79290008544922, MaskLoss: 0.6001354455947876, Test Loss: 0.30345556139945984, Test Accuracy: 99.2404556274414\n","Epoch 18, Loss: 0.2788638174533844, Accuracy: 99.80973815917969, MaskLoss: 0.5880311727523804, Test Loss: 0.28542882204055786, Test Accuracy: 99.21875\n","Epoch 19, Loss: 0.2585771679878235, Accuracy: 99.82994079589844, MaskLoss: 0.5879595279693604, Test Loss: 0.2630130350589752, Test Accuracy: 99.15364074707031\n","Epoch 20, Loss: 0.2339620143175125, Accuracy: 99.83667755126953, MaskLoss: 0.5880321860313416, Test Loss: 0.2410130500793457, Test Accuracy: 99.25129699707031\n","Epoch 21, Loss: 0.21709755063056946, Accuracy: 99.84846496582031, MaskLoss: 0.5866191983222961, Test Loss: 0.2216225266456604, Test Accuracy: 99.37065887451172\n","Epoch 22, Loss: 0.19943095743656158, Accuracy: 99.88887023925781, MaskLoss: 0.5904545783996582, Test Loss: 0.20532210171222687, Test Accuracy: 99.2947006225586\n","Epoch 23, Loss: 0.1836351901292801, Accuracy: 99.90066528320312, MaskLoss: 0.5895957946777344, Test Loss: 0.19515304267406464, Test Accuracy: 99.31640625\n","Epoch 24, Loss: 0.17085033655166626, Accuracy: 99.92759704589844, MaskLoss: 0.5880869626998901, Test Loss: 0.18111735582351685, Test Accuracy: 99.42491149902344\n","Epoch 25, Loss: 0.16240538656711578, Accuracy: 99.90570831298828, MaskLoss: 0.5868381261825562, Test Loss: 0.17272460460662842, Test Accuracy: 99.34895324707031\n","Epoch 26, Loss: 0.15159262716770172, Accuracy: 99.91918182373047, MaskLoss: 0.5838077664375305, Test Loss: 0.1670287400484085, Test Accuracy: 99.31640625\n","Epoch 27, Loss: 0.1417360007762909, Accuracy: 99.92591857910156, MaskLoss: 0.5855788588523865, Test Loss: 0.1581953465938568, Test Accuracy: 99.31640625\n","Epoch 28, Loss: 0.13407187163829803, Accuracy: 99.92086029052734, MaskLoss: 0.5851085782051086, Test Loss: 0.15092915296554565, Test Accuracy: 99.38151550292969\n","Epoch 29, Loss: 0.12480688095092773, Accuracy: 99.94780731201172, MaskLoss: 0.5862746238708496, Test Loss: 0.14424973726272583, Test Accuracy: 99.32725524902344\n","Epoch 30, Loss: 0.12104585021734238, Accuracy: 99.94780731201172, MaskLoss: 0.5827796459197998, Test Loss: 0.13339467346668243, Test Accuracy: 99.35980987548828\n","Epoch 31, Loss: 0.10916870832443237, Accuracy: 99.94949340820312, MaskLoss: 0.5961131453514099, Test Loss: 0.12405538558959961, Test Accuracy: 99.3923568725586\n","Epoch 32, Loss: 0.10356169939041138, Accuracy: 99.95285034179688, MaskLoss: 0.5882107019424438, Test Loss: 0.12418462336063385, Test Accuracy: 99.34895324707031\n","Epoch 33, Loss: 0.10189073532819748, Accuracy: 99.951171875, MaskLoss: 0.5826944708824158, Test Loss: 0.1225370541214943, Test Accuracy: 99.25129699707031\n","Epoch 34, Loss: 0.09573472291231155, Accuracy: 99.96127319335938, MaskLoss: 0.5840350985527039, Test Loss: 0.11077046394348145, Test Accuracy: 99.34895324707031\n","Epoch 35, Loss: 0.0878547802567482, Accuracy: 99.97306060791016, MaskLoss: 0.5879980325698853, Test Loss: 0.10826894640922546, Test Accuracy: 99.34895324707031\n","Epoch 36, Loss: 0.08509893715381622, Accuracy: 99.9579086303711, MaskLoss: 0.5865435004234314, Test Loss: 0.10325086861848831, Test Accuracy: 99.37065887451172\n","Epoch 37, Loss: 0.08024788647890091, Accuracy: 99.96800994873047, MaskLoss: 0.5847809314727783, Test Loss: 0.09954629838466644, Test Accuracy: 99.42491149902344\n","Epoch 38, Loss: 0.07814580202102661, Accuracy: 99.97306060791016, MaskLoss: 0.5795983076095581, Test Loss: 0.09631653130054474, Test Accuracy: 99.47917175292969\n","Epoch 39, Loss: 0.07346119731664658, Accuracy: 99.97979736328125, MaskLoss: 0.586974024772644, Test Loss: 0.09188137203454971, Test Accuracy: 99.38151550292969\n","Epoch 40, Loss: 0.06862969696521759, Accuracy: 99.96295928955078, MaskLoss: 0.5878039598464966, Test Loss: 0.08744367957115173, Test Accuracy: 99.40321350097656\n","Epoch 41, Loss: 0.06442661583423615, Accuracy: 99.97306060791016, MaskLoss: 0.5898030996322632, Test Loss: 0.08015208691358566, Test Accuracy: 99.52256774902344\n","Epoch 42, Loss: 0.062288619577884674, Accuracy: 99.97474670410156, MaskLoss: 0.5869655013084412, Test Loss: 0.08007710427045822, Test Accuracy: 99.42491149902344\n","Epoch 43, Loss: 0.05991264432668686, Accuracy: 99.9579086303711, MaskLoss: 0.5861839056015015, Test Loss: 0.08001475781202316, Test Accuracy: 99.3923568725586\n","Epoch 44, Loss: 0.056584715843200684, Accuracy: 99.98148345947266, MaskLoss: 0.5847946405410767, Test Loss: 0.0772988423705101, Test Accuracy: 99.3923568725586\n","Epoch 45, Loss: 0.05516437068581581, Accuracy: 99.97979736328125, MaskLoss: 0.5814555883407593, Test Loss: 0.0748252421617508, Test Accuracy: 99.42491149902344\n","Epoch 46, Loss: 0.05482514202594757, Accuracy: 99.95453643798828, MaskLoss: 0.5806416273117065, Test Loss: 0.0756131112575531, Test Accuracy: 99.37065887451172\n","Epoch 47, Loss: 0.05128499120473862, Accuracy: 99.97306060791016, MaskLoss: 0.5797879695892334, Test Loss: 0.07372648268938065, Test Accuracy: 99.40321350097656\n","Epoch 48, Loss: 0.04834461957216263, Accuracy: 99.97811126708984, MaskLoss: 0.5816305875778198, Test Loss: 0.06759467720985413, Test Accuracy: 99.40321350097656\n","Epoch 49, Loss: 0.0447651632130146, Accuracy: 99.96968841552734, MaskLoss: 0.5831267833709717, Test Loss: 0.06564678996801376, Test Accuracy: 99.40321350097656\n","Epoch 50, Loss: 0.043745651841163635, Accuracy: 99.97979736328125, MaskLoss: 0.5807359218597412, Test Loss: 0.06781762838363647, Test Accuracy: 99.34895324707031\n"]}]}]}