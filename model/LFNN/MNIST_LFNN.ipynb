{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vroxxU1Mia53"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "def preprocess_images(images):\n",
        "  images = images.reshape((images.shape[0], 28,28)) / 255.\n",
        "  return images\n",
        "\n",
        "\n",
        "train_images = preprocess_images(train_images)\n",
        "test_images = preprocess_images(test_images)\n",
        "\n",
        "train_labels = np.expand_dims(train_labels,axis=-1)\n",
        "test_labels = np.expand_dims(test_labels,axis=-1)\n",
        "train_size = 60000\n",
        "batch_size = 200\n",
        "test_size = 10000\n",
        "\n",
        "\n",
        "train_images = tf.expand_dims(train_images, axis = -1)\n",
        "test_images = tf.expand_dims(test_images, axis = -1)"
      ],
      "metadata": {
        "id": "gWJyaObmidrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = (tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "                 .shuffle(train_size,reshuffle_each_iteration=True).batch(batch_size,drop_remainder=True))\n",
        "test_dataset = (tf.data.Dataset.from_tensor_slices((test_images,test_labels))\n",
        "                .shuffle(test_size).batch(batch_size,drop_remainder=True))"
      ],
      "metadata": {
        "id": "RLpHtoDrieVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels.shape, train_images.shape"
      ],
      "metadata": {
        "id": "j1hklQlEifdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VUnEnEc7hOj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "metadata": {
        "id": "cFhcjyaogR6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CustomDropout(tf.keras.layers.Layer):\n",
        "    def __init__(self, rate, input_dim, **kwargs):\n",
        "        super(CustomDropout, self).__init__(**kwargs)\n",
        "        self.rate = 1-rate\n",
        "        self.input_dim = input_dim\n",
        "        self.mask_w = self.add_weight(shape=(self.input_dim,n_decision_makers), trainable=True)\n",
        "        self.mask_b = self.add_weight(shape=(n_decision_makers,), initializer=\"zeros\",trainable=True)\n",
        "\n",
        "\n",
        "    def call(self, inputs, label, training=None):\n",
        "        if training:\n",
        "\n",
        "          scce = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
        "\n",
        "          loss = scce(tf.tile(tf.transpose([label],perm = [1,2,0]),[1,n_decision_makers,1]),inputs)\n",
        "\n",
        "          threshold = tfp.stats.percentile(loss, q=self.rate*100)\n",
        "          dropout_mask = (loss<=threshold) ## <= 1-rate keep the best 10%\n",
        "\n",
        "          mask = tf.tile(tf.expand_dims(dropout_mask, axis=-1), [1,1,10])\n",
        "\n",
        "          mask_pred = tf.nn.sigmoid(tf.matmul(tf.keras.layers.Flatten()(inputs), self.mask_w)+self.mask_b)\n",
        "          mask_pred = tf.tile(mask_pred, [1,10])\n",
        "          return tf.multiply(tf.keras.layers.Reshape((n_decision_makers,10))(mask_pred), inputs), tf.cast(mask,'float32'), mask_pred\n",
        "\n",
        "        else:\n",
        "          mask_pred = tf.nn.sigmoid(tf.matmul(tf.keras.layers.Flatten()(inputs), self.mask_w)+self.mask_b)\n",
        "          mask_pred = tf.tile(mask_pred, [1,10])\n",
        "          return tf.multiply(tf.keras.layers.Reshape((n_decision_makers,10))(mask_pred),inputs),tf.ones(shape = (batch_size,n_decision_makers,10)),mask_pred ## reshape self.mask"
      ],
      "metadata": {
        "id": "e_Fj3dtLgTHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CustomDropout(tf.keras.layers.Layer):\n",
        "    def __init__(self, rate, input_dim, **kwargs):\n",
        "        super(CustomDropout, self).__init__(**kwargs)\n",
        "        self.rate = 1-rate\n",
        "        self.input_dim = input_dim\n",
        "        self.mask_w = self.add_weight(shape=(self.input_dim,n_decision_makers), trainable=True)\n",
        "        self.mask_b = self.add_weight(shape=(n_decision_makers,), initializer=\"zeros\",trainable=True)\n",
        "\n",
        "    def call(self, inputs, label, training=None):\n",
        "\n",
        "        if training:\n",
        "          scce = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
        "          loss = scce(tf.tile(tf.transpose([label],perm = [1,2,0]),[1,n_decision_makers,1]),inputs)\n",
        "          threshold = tfp.stats.percentile(loss, q=self.rate*100)\n",
        "          dropout_mask = (loss<=threshold)\n",
        "          mask = tf.tile(tf.expand_dims(dropout_mask, axis=-1), [1,1,10])\n",
        "          mask_pred = tf.nn.sigmoid(tf.matmul(tf.keras.layers.Flatten()(inputs), self.mask_w)+self.mask_b)\n",
        "          mask_pred = tf.tile(mask_pred, [1,10])\n",
        "          return tf.multiply(tf.keras.layers.Reshape((n_decision_makers,10))(mask_pred), inputs), tf.cast(mask,'float32'), mask_pred\n",
        "        else:\n",
        "          mask_pred = tf.nn.sigmoid(tf.matmul(tf.keras.layers.Flatten()(inputs), self.mask_w)+self.mask_b)\n",
        "          mask_pred = tf.tile(mask_pred, [1,10])\n",
        "          return tf.multiply(tf.keras.layers.Reshape((n_decision_makers,10))(mask_pred),inputs),tf.ones(shape = (batch_size,n_decision_makers,10)),mask_pred ## reshape self.mask"
      ],
      "metadata": {
        "id": "JR8nmWt3guXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_decision_makers = 4  #100\n",
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self,**kwargs):\n",
        "      super(MyModel,self).__init__(**kwargs)\n",
        "\n",
        "      self.flat1 = tf.keras.layers.Flatten()\n",
        "      self.flat2 = tf.keras.layers.Flatten()\n",
        "      self.flat3 = tf.keras.layers.Flatten()\n",
        "      self.flat4 = tf.keras.layers.Flatten()\n",
        "      self.flat5 = tf.keras.layers.Flatten()\n",
        "      self.flat6 = tf.keras.layers.Flatten()\n",
        "      self.reshape1 = tf.keras.layers.Reshape((n_decision_makers,10))\n",
        "      self.reshape2 = tf.keras.layers.Reshape((n_decision_makers,10))\n",
        "\n",
        "\n",
        "\n",
        "      self.dropout1 = CustomDropout(0.7,n_decision_makers*10)\n",
        "      self.dropout4 = tf.keras.layers.Dropout(0.2)\n",
        "      self.dropout5 = tf.keras.layers.Dropout(0.2)\n",
        "\n",
        "      self.pool1 = tf.keras.layers.MaxPooling2D((2, 2))\n",
        "      self.pool2 = tf.keras.layers.MaxPooling2D((2, 2))\n",
        "\n",
        "      self.conv1 = tf.keras.layers.Conv2D(64, 3, activation='relu',padding='same',kernel_regularizer=tf.keras.regularizers.l1(l=0.01),kernel_initializer='he_uniform',)\n",
        "      self.conv11 = tf.keras.layers.Conv2D(128, 3, activation='relu',padding='same',kernel_regularizer=tf.keras.regularizers.l1(l=0.01),kernel_initializer='he_uniform',)\n",
        "      self.dense1 = tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n",
        "      self.batchnorm1 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "      self.conv2 = tf.keras.layers.Conv2D(128, 3, activation='relu',padding='same',kernel_regularizer=tf.keras.regularizers.l1(l=0.01),kernel_initializer='he_uniform',)\n",
        "      self.conv22 = tf.keras.layers.Conv2D(64, 3, activation='relu',padding='same',kernel_regularizer=tf.keras.regularizers.l1(l=0.01),kernel_initializer='he_uniform',)\n",
        "      self.dense2 = tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n",
        "      self.batchnorm2 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "      self.dense5 = tf.keras.layers.Dense(n_decision_makers*10,activation=tf.nn.relu)\n",
        "      self.dense7 = tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "\n",
        "    def call(self, input):\n",
        "\n",
        "      [input, label] = input\n",
        "      hidden_conv1 = self.dropout4(self.batchnorm1(self.pool1(self.conv1(self.conv11(input)))))\n",
        "      hidden_conv1_reshape = self.flat4(hidden_conv1)\n",
        "      hidden_conv1_out = self.dense1(hidden_conv1_reshape)\n",
        "\n",
        "      hidden_conv2 = self.dropout5(self.batchnorm2(self.pool2(self.conv2(self.conv22(hidden_conv1)))))\n",
        "      hidden_conv2_reshape = self.flat5(hidden_conv2)\n",
        "      hidden_conv2_out = self.dense2(hidden_conv2_reshape)\n",
        "\n",
        "      hidden1 = self.dense5(hidden_conv2_reshape)\n",
        "      hidden1_reshape = self.reshape1(hidden1)\n",
        "      hidden1_softmax = tf.nn.softmax(hidden1_reshape)\n",
        "      hidden1_out,hidden1_true_mask,hidden1_pred_mask = self.dropout1(hidden1_softmax,label)\n",
        "\n",
        "      outputs = self.dense7(self.flat1(hidden1_out)) #leader outputs\n",
        "\n",
        "      return outputs"
      ],
      "metadata": {
        "id": "Xrh9nKBQg-CP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel()\n",
        "model([tf.zeros((batch_size, 28, 28, 1)),tf.zeros((batch_size, 1))])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "gZ4fQprxg_1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "\t optimizer='adam',\n",
        "\t metrics='acc')\n",
        "\n",
        "model.fit([train_images, train_labels], train_labels,\n",
        "\t validation_data=([test_images, np.zeros(test_labels.shape)],test_labels),\n",
        "\t epochs=100,\n",
        "\t batch_size=batch_size,\n",
        ")"
      ],
      "metadata": {
        "id": "-3H8Ps8PhDvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "local_loss"
      ],
      "metadata": {
        "id": "C8UDXjuSmqKu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tko6VF29kaGl"
      }
    }
  ]
}